中文
|
English
网站首页
学院概况
学院简介
历史沿革
现任领导
机构设置
办学资源
学科情况
联系方式
师生意见箱
师资中心
师资概况
教职工名单
导师简介
兼职师资
科学研究
研究中心
科研机构
科研项目
科研论文
知识产权
科研政策
人才培养
审核评估专题
博士生
硕士生
本科生
图灵班
图灵讲堂
卓越工程师班
国际交流
党群工作
学院党委
基层组织
分党校工作
发展工作
关工委工作
规章制度
专题活动
学习园地
全省党建工作样板支部...
苏州大学教师党支部书...
工会工作
学生工作
学生科创
工作队伍
学工通知
学工新闻
规章制度
志愿服务
学生组织
勤工助学
心理健康
就业创业
成长陪伴
家校平台
合作交流
校企合作与交流
国际合作与交流
保密学院
学院简介
保密培训
保密研究
继续教育
成教工作
自考工作
培训工作
留学项目
在线课程
校友工作
校友服务
毕业校友录
校友活动
校友会
我院肖义胜等学生论文被国际顶会ICLR’2024接收
时间:2024-01-18
发布者:李俊涛
文章来源:计算机科学与技术学院
审核人:黄河、李恩秀
浏览次数:2657
我院博士一年级学生肖义胜所著论文《AreBertFamilyGoodInstructionFollowers?AStudyonTheirPotentialAndLimitations》被ICLR’2024接收，此论文为我校第一单位的首篇ICLR论文，通讯作者为李俊涛老师。ICLR的全称是国际表示学习会议（InternationalConferenceonLearningRepresentations），与NeurIPS和ICML并称为深度学习的三大顶级会议。该论文第一作者肖义胜为我院17级软件工程专业本科生，21年保研留校（导师张民，李俊涛协助指导），23年转为硕博连读，主要研究语言建模的新框架与推理策略，曾发表我校首篇学生一作TPAMI论文（CCFA类期刊，影响因子24.3），另外在AAAI、EMNLP等国际顶会上发表多篇论文。该工作在肖义胜同学前期研究工作的基础上重点探索了GPT系列和T5系列大模型以外的其它可能性，首次对BERT系列模型的zero-shot指令跟随（instructionfollowing）进行了探索。实验结果表明，通过提出简单的策略即可使得BERT系列模型具备与同等大小的T5和GPT系列生成式模型相当的zero-shot生成和指令遵循能力，并且具备3倍以上的解码速度提升。该研究为生成式语言模型的框架设计提供了新的可能性，并指明了接下来需要解决的难题。
联系方式：0512-65113107
联系地址：苏州市干将东路333号
邮编：215008
院长信箱：scst@suda.edu.cn
